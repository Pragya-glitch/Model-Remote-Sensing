{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a simple implementation of the SRGAN super resolution architecture. Further Improvements need to be done. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key takeaways from the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ability of Mean Squared Error, Peak Signal to Noise Ratio to capture 'perceptually relevant'(like texture for instance) differences like high texture details is limited as both are based on pixel wise image differences. \n",
    "\n",
    "- Super resolved image may not be as photo realistic as the original image. \n",
    "\n",
    "- A Super Resolution Generative Adversarial Network is proposed, in which a deep residual network(ResNet) with skip connections. \n",
    "\n",
    "- A novel loss function is also proposed which uses high level feature maps of the VGG network. \n",
    "\n",
    "- Low resolution images were obtained by applying a Gaussian filter to the High Resolution Image, proceeded by a downsampling with a factor of r. \n",
    "\n",
    "- The ParametricReLU is used as the activation function. \n",
    "\n",
    "- The perceptual loss function was defined as a sum of content loss and adversarial loss. Weightage of the loss function is $1 : \\frac{1}{1000}$(content loss : adversarial loss)\n",
    "\n",
    "- Perceptual Loss > can use many humans to eval images, a far practical method is to use a pre trained network that has been trained on millions of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Things to read up on:\n",
    "- MSE, PSNR \n",
    "- ResNet, skip connections\n",
    "- Loss functions\n",
    "- feature maps, vgg network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tI0KcjC3auG4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x26f03e78fd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import Compose, RandomCrop, ToTensor, ToPILImage, CenterCrop, Resize\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from os.path import join\n",
    "from torch import nn, optim\n",
    "from torchvision.models.vgg import vgg16\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from scipy.ndimage import rotate\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Y9gCiSoBdnXC"
   },
   "outputs": [],
   "source": [
    "UPSCALE_FACTOR = 4\n",
    "CROP_SIZE = 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1JxvJbk7dqlY"
   },
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains code for the dataloader needed for the data in the folder. This is a custom implementation of the `TrainDatasetFromFolder` class, which inherits from the original class in the `pytorch` library. The dataloader returns a HR(High Resolution, which is the image at its original resolution) image and an LR image(which has been resized to introduce image degradation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we used in this notebook is the [DIV2K](https://data.vision.ee.ethz.ch/cvl/DIV2K/) dataset, which contains 1000 images of 2K resolution(800 training images, 100 validation images, 100 testing images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
    "    return crop_size - (crop_size % upscale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hr_transform(crop_size):\n",
    "    return Compose([\n",
    "        RandomCrop(crop_size),\n",
    "        ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lr_transform(crop_size, upscale_factor):\n",
    "    return Compose([\n",
    "        ToPILImage(),\n",
    "        Resize(crop_size // upscale_factor, interpolation=Image.BICUBIC),\n",
    "        ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_transform():\n",
    "    return Compose([\n",
    "        ToPILImage(),\n",
    "        Resize(400),\n",
    "        CenterCrop(400),\n",
    "        ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "N0tpRB2Jdys4"
   },
   "outputs": [],
   "source": [
    "class TrainDatasetFromFolder(Dataset):\n",
    "    def __init__(self, dataset_dir, crop_size, upscale_factor):\n",
    "        super(TrainDatasetFromFolder, self).__init__()\n",
    "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
    "        crop_size = calculate_valid_crop_size(crop_size, upscale_factor)\n",
    "        self.hr_transform = train_hr_transform(crop_size)\n",
    "        self.lr_transform = train_lr_transform(crop_size, upscale_factor)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hr_image = self.hr_transform(Image.open(self.image_filenames[index]))\n",
    "        lr_image = self.lr_transform(hr_image)\n",
    "        return lr_image, hr_image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "re2-OAGQv-aQ",
    "outputId": "c728e7af-8eac-4f92-b125-5342ccf6586d"
   },
   "outputs": [],
   "source": [
    "train_set = TrainDatasetFromFolder(\"DIV2K_train_HR\", crop_size=CROP_SIZE,\n",
    "                                   upscale_factor=UPSCALE_FACTOR)\n",
    "trainloader = DataLoader(train_set, batch_size=64, num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cA8VHoPTwMaz"
   },
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SRGAN Model Architecture](srgan.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first major block consists of a sequence of residual blocks, after the input layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Residual Block?\n",
    "\n",
    "A Residual block consists of the following components:\n",
    "- A series of convolutional layers that are responsible for extracting features from the input data. \n",
    "- Batch normalisation is applied after each convolutional layer. This helps in stabilising and accelerating training by normalising the input to the following layer. \n",
    "- Activation functions are applied to introduce non linearity in the network, which allows the network to learn complex and non linear patterns in the data. \n",
    "- Skip Connection is essentially the sum of the input of the block and the output of the last batch normalisation layer, allows gradients to flow more freely throught the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Read up on the Vanishing Gradient Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DQGAwDSGwUnE"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "  def __init__(self, channels):\n",
    "    super(ResidualBlock, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "    self.bn1 = nn.BatchNorm2d(channels)\n",
    "    self.prelu = nn.PReLU()\n",
    "    self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "    self.bn2 = nn.BatchNorm2d(channels)\n",
    "  def forward(self, x):\n",
    "    residual = self.conv1(x)\n",
    "    residual = self.bn1(residual)\n",
    "    residual = self.prelu(residual)\n",
    "    residual = self.conv2(residual)\n",
    "    residual = self.bn2(residual)\n",
    "    return x + residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block in the generator is the upscaling block. The upsaming block is comprises of an initial convolution layer, which feeds into a pixel shuffle layer, and then lastly fed into a ParametricReLU activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GNpcnPmbw6QQ"
   },
   "outputs": [],
   "source": [
    "class UpsampleBlock(nn.Module):\n",
    "  def __init__(self, in_channels, up_scale):\n",
    "    super(UpsampleBlock, self).__init__()\n",
    "    self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2,\n",
    "                          kernel_size=3, padding=1)\n",
    "    self.pixel_shuffle = nn.PixelShuffle(up_scale)\n",
    "    self.prelu = nn.PReLU()\n",
    "  def forward(self, x):\n",
    "    x = self.conv(x)\n",
    "    x = self.pixel_shuffle(x)\n",
    "    x = self.prelu(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZZnfl5c0uzUI"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "  def __init__(self, scale_factor):\n",
    "    super(Generator, self).__init__()\n",
    "    upsample_block_num = int(math.log(scale_factor, 2))\n",
    "\n",
    "    self.block1 = nn.Sequential(\n",
    "        nn.Conv2d(3, 64, kernel_size=9, padding=4),\n",
    "        nn.PReLU()\n",
    "    )\n",
    "\n",
    "    self.block2 = ResidualBlock(64)\n",
    "    self.block3 = ResidualBlock(64)\n",
    "    self.block4 = ResidualBlock(64)\n",
    "    self.block5 = ResidualBlock(64)\n",
    "    self.block6 = ResidualBlock(64)\n",
    "    self.block7 = nn.Sequential(\n",
    "        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64)\n",
    "    )\n",
    "    block8 = [UpsampleBlock(64, 2) for _ in range(upsample_block_num)]\n",
    "    block8.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))\n",
    "    self.block8 = nn.Sequential(*block8)\n",
    "  def forward(self, x):\n",
    "    block1 = self.block1(x)\n",
    "    block2 = self.block2(block1)\n",
    "    block3 = self.block3(block2)\n",
    "    block4 = self.block4(block3)\n",
    "    block5 = self.block5(block4)\n",
    "    block6 = self.block6(block5)\n",
    "    block7 = self.block7(block6)\n",
    "    block8 = self.block8(block1 + block7)\n",
    "    return (torch.tanh(block8) + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ue5xbeyUuzWF"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Discriminator, self).__init__()\n",
    "    self.net = nn.Sequential(\n",
    "        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        nn.Conv2d(512, 1024, kernel_size=1),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv2d(1024, 1, kernel_size=1)\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    batch_size=x.size()[0]\n",
    "    return torch.sigmoid(self.net(x).view(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper proposed a perceptual loss function, which consists of an adversarial loss and a content loss. The content loss is motivated by the perceptual similarity insteam of pixel space similarity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RamJwy7yxitq"
   },
   "outputs": [],
   "source": [
    "class TVLoss(nn.Module):\n",
    "  def __init__(self, tv_loss_weight=1):\n",
    "    super(TVLoss, self).__init__()\n",
    "    self.tv_loss_weight=tv_loss_weight\n",
    "  def forward(self, x):\n",
    "    batch_size=x.size()[0]\n",
    "    h_x = x.size()[2]\n",
    "    w_x = x.size()[3]\n",
    "\n",
    "    count_h = self.tensor_size(x[:, :, 1:, :])\n",
    "    count_w = self.tensor_size(x[:, :, :, 1:])\n",
    "\n",
    "    h_tv = torch.pow(x[:, :, 1:, :] - x[:, :, :h_x - 1, :], 2).sum()\n",
    "    w_tv = torch.pow(x[:, :, :, 1:] - x[:, :, :, :w_x - 1], 2).sum()\n",
    "    return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
    "\n",
    "  @staticmethod # Must add this\n",
    "  def tensor_size(t):\n",
    "    return t.size()[1] * t.size()[2] * t.size()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OiwFaF3tySU_"
   },
   "outputs": [],
   "source": [
    "class GeneratorLoss(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(GeneratorLoss, self).__init__()\n",
    "    vgg = vgg16(pretrained=True)\n",
    "    loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
    "    for param in loss_network.parameters():\n",
    "      param.requires_grad = False\n",
    "    self.loss_network = loss_network\n",
    "    self.mse_loss = nn.MSELoss()\n",
    "    self.tv_loss = TVLoss()\n",
    "  def forward(self, out_labels, out_images, target_images):\n",
    "    adversial_loss = torch.mean(1 - out_labels)\n",
    "    perception_loss = self.mse_loss(out_images, target_images)\n",
    "    image_loss = self.mse_loss(out_images, target_images)\n",
    "    tv_loss = self.tv_loss(out_images)\n",
    "    return image_loss + 0.001 * adversial_loss + 0.006 * perception_loss + 2e-8 * tv_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzzSCJjjy7I9",
    "outputId": "50699703-68e5-4767-d034-d029bfdb66be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Standard device selectoin\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4oGBnX7PLGJ-"
   },
   "outputs": [],
   "source": [
    "netG = Generator(UPSCALE_FACTOR)\n",
    "netD = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n39cIDQeLJFO",
    "outputId": "1ed2620f-7ef2-4329-8335-152d9b5e8b15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python Notebooks\\R&D - Image Super Resolution\\SRGAN\\srgan\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\Python Notebooks\\R&D - Image Super Resolution\\SRGAN\\srgan\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "generator_criterion = GeneratorLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "7ynXcO-8LSgN"
   },
   "outputs": [],
   "source": [
    "generator_criterion = generator_criterion.to(device)\n",
    "netG = netG.to(device)\n",
    "netD = netD.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "gDlYj1loLiD_"
   },
   "outputs": [],
   "source": [
    "optimizerG = optim.Adam(netG.parameters(), lr=0.0002)\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "doBMeLWOLs_0"
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"d_loss\":[],\n",
    "    \"g_loss\":[],\n",
    "    \"d_score\": [],\n",
    "    \"g_score\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "BeTxlp0eML1d"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 150 # 150 is good enough for our model. gives decent enough results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCheckpoint(model, optimizer, filename):\n",
    "    print('===> saving checkpoint')\n",
    "    checkpoint = {\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCheckpoint(checkpoint_file, model, optimizer, lr): \n",
    "    print('===> load checkpoint')\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=config.DEVICE)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "    for param_group in optimizer.param_groups:      # needed or model will have learning rate of older checkpoint \n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHadZtxcMO01",
    "outputId": "45a6effa-74c9-40a7-84d7-1d0bda73e926",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/150] Loss_D: 0.7994 Loss_G: 0.0412 D(x): 0.5923 D(G(z)): 0.5923: 100%|██████████████| 13/13 [01:48<00:00,  8.35s/it]\n",
      "[2/150] Loss_D: 0.5155 Loss_G: 0.0173 D(x): 0.7294 D(G(z)): 0.7294: 100%|██████████████| 13/13 [01:25<00:00,  6.56s/it]\n",
      "[3/150] Loss_D: 0.3522 Loss_G: 0.0149 D(x): 0.8116 D(G(z)): 0.8116: 100%|██████████████| 13/13 [01:31<00:00,  7.06s/it]\n",
      "[4/150] Loss_D: 0.2502 Loss_G: 0.0128 D(x): 0.8766 D(G(z)): 0.8766: 100%|██████████████| 13/13 [01:25<00:00,  6.61s/it]\n",
      "[5/150] Loss_D: 0.0844 Loss_G: 0.0115 D(x): 0.9532 D(G(z)): 0.9532: 100%|██████████████| 13/13 [01:43<00:00,  7.98s/it]\n",
      "[6/150] Loss_D: 0.0546 Loss_G: 0.0104 D(x): 0.9706 D(G(z)): 0.9706: 100%|██████████████| 13/13 [01:28<00:00,  6.77s/it]\n",
      "[7/150] Loss_D: 0.6345 Loss_G: 0.0108 D(x): 0.5194 D(G(z)): 0.5194: 100%|██████████████| 13/13 [01:36<00:00,  7.44s/it]\n",
      "[8/150] Loss_D: 0.7253 Loss_G: 0.0098 D(x): 0.4340 D(G(z)): 0.4340: 100%|██████████████| 13/13 [01:28<00:00,  6.82s/it]\n",
      "[9/150] Loss_D: 0.6795 Loss_G: 0.0103 D(x): 0.5388 D(G(z)): 0.5388: 100%|██████████████| 13/13 [01:28<00:00,  6.84s/it]\n",
      "[10/150] Loss_D: 0.3807 Loss_G: 0.0089 D(x): 0.7149 D(G(z)): 0.7149: 100%|█████████████| 13/13 [01:28<00:00,  6.81s/it]\n",
      "[11/150] Loss_D: 0.3654 Loss_G: 0.0107 D(x): 0.8763 D(G(z)): 0.8763: 100%|█████████████| 13/13 [01:38<00:00,  7.59s/it]\n",
      "[12/150] Loss_D: 0.1191 Loss_G: 0.0083 D(x): 0.9372 D(G(z)): 0.9372: 100%|█████████████| 13/13 [01:21<00:00,  6.28s/it]\n",
      "[13/150] Loss_D: 0.0821 Loss_G: 0.0081 D(x): 0.9579 D(G(z)): 0.9579: 100%|█████████████| 13/13 [01:39<00:00,  7.62s/it]\n",
      "[14/150] Loss_D: 0.2354 Loss_G: 0.0080 D(x): 0.9640 D(G(z)): 0.9640: 100%|█████████████| 13/13 [01:31<00:00,  7.02s/it]\n",
      "[15/150] Loss_D: 0.8287 Loss_G: 0.0073 D(x): 0.9172 D(G(z)): 0.9172: 100%|█████████████| 13/13 [01:33<00:00,  7.16s/it]\n",
      "[16/150] Loss_D: 0.2798 Loss_G: 0.0085 D(x): 0.8683 D(G(z)): 0.8683: 100%|█████████████| 13/13 [01:27<00:00,  6.73s/it]\n",
      "[17/150] Loss_D: 0.1819 Loss_G: 0.0073 D(x): 0.9222 D(G(z)): 0.9222: 100%|█████████████| 13/13 [01:34<00:00,  7.29s/it]\n",
      "[18/150] Loss_D: 0.0362 Loss_G: 0.0072 D(x): 0.9754 D(G(z)): 0.9754: 100%|█████████████| 13/13 [01:22<00:00,  6.38s/it]\n",
      "[19/150] Loss_D: 0.0206 Loss_G: 0.0070 D(x): 0.9861 D(G(z)): 0.9861: 100%|█████████████| 13/13 [01:36<00:00,  7.43s/it]\n",
      "[20/150] Loss_D: 0.0119 Loss_G: 0.0072 D(x): 0.9938 D(G(z)): 0.9938: 100%|█████████████| 13/13 [01:28<00:00,  6.81s/it]\n",
      "[21/150] Loss_D: 0.0089 Loss_G: 0.0069 D(x): 0.9941 D(G(z)): 0.9941: 100%|█████████████| 13/13 [01:35<00:00,  7.34s/it]\n",
      "[22/150] Loss_D: 0.0075 Loss_G: 0.0071 D(x): 0.9948 D(G(z)): 0.9948: 100%|█████████████| 13/13 [01:24<00:00,  6.49s/it]\n",
      "[23/150] Loss_D: 0.0073 Loss_G: 0.0066 D(x): 0.9957 D(G(z)): 0.9957: 100%|█████████████| 13/13 [01:36<00:00,  7.39s/it]\n",
      "[24/150] Loss_D: 0.0075 Loss_G: 0.0069 D(x): 0.9975 D(G(z)): 0.9975: 100%|█████████████| 13/13 [01:23<00:00,  6.40s/it]\n",
      "[25/150] Loss_D: 0.0069 Loss_G: 0.0061 D(x): 0.9962 D(G(z)): 0.9962: 100%|█████████████| 13/13 [01:40<00:00,  7.74s/it]\n",
      "[26/150] Loss_D: 0.0048 Loss_G: 0.0061 D(x): 0.9978 D(G(z)): 0.9978: 100%|█████████████| 13/13 [01:31<00:00,  7.07s/it]\n",
      "[27/150] Loss_D: 0.0035 Loss_G: 0.0067 D(x): 0.9989 D(G(z)): 0.9989: 100%|█████████████| 13/13 [01:28<00:00,  6.78s/it]\n",
      "[28/150] Loss_D: 0.0025 Loss_G: 0.0068 D(x): 0.9985 D(G(z)): 0.9985: 100%|█████████████| 13/13 [01:24<00:00,  6.51s/it]\n",
      "[29/150] Loss_D: 0.0081 Loss_G: 0.0065 D(x): 0.9941 D(G(z)): 0.9941: 100%|█████████████| 13/13 [01:31<00:00,  7.05s/it]\n",
      "[30/150] Loss_D: 0.0051 Loss_G: 0.0067 D(x): 0.9977 D(G(z)): 0.9977: 100%|█████████████| 13/13 [01:41<00:00,  7.81s/it]\n",
      "[31/150] Loss_D: 0.0040 Loss_G: 0.0066 D(x): 0.9981 D(G(z)): 0.9981: 100%|█████████████| 13/13 [01:36<00:00,  7.43s/it]\n",
      "[32/150] Loss_D: 0.0035 Loss_G: 0.0059 D(x): 0.9985 D(G(z)): 0.9985: 100%|█████████████| 13/13 [01:27<00:00,  6.71s/it]\n",
      "[33/150] Loss_D: 0.0036 Loss_G: 0.0064 D(x): 0.9981 D(G(z)): 0.9981: 100%|█████████████| 13/13 [01:34<00:00,  7.25s/it]\n",
      "[34/150] Loss_D: 0.0035 Loss_G: 0.0061 D(x): 0.9989 D(G(z)): 0.9989: 100%|█████████████| 13/13 [01:25<00:00,  6.55s/it]\n",
      "[35/150] Loss_D: 0.0037 Loss_G: 0.0059 D(x): 0.9977 D(G(z)): 0.9977: 100%|█████████████| 13/13 [01:42<00:00,  7.90s/it]\n",
      "[36/150] Loss_D: 0.0027 Loss_G: 0.0062 D(x): 0.9983 D(G(z)): 0.9983: 100%|█████████████| 13/13 [01:28<00:00,  6.78s/it]\n",
      "[37/150] Loss_D: 0.0060 Loss_G: 0.0062 D(x): 0.9984 D(G(z)): 0.9984: 100%|█████████████| 13/13 [01:31<00:00,  7.05s/it]\n",
      "[38/150] Loss_D: 0.0037 Loss_G: 0.0059 D(x): 0.9978 D(G(z)): 0.9978: 100%|█████████████| 13/13 [01:24<00:00,  6.49s/it]\n",
      "[39/150] Loss_D: 0.0018 Loss_G: 0.0054 D(x): 0.9990 D(G(z)): 0.9990: 100%|█████████████| 13/13 [01:40<00:00,  7.76s/it]\n",
      "[40/150] Loss_D: 0.0054 Loss_G: 0.0066 D(x): 0.9963 D(G(z)): 0.9963: 100%|█████████████| 13/13 [01:39<00:00,  7.67s/it]\n",
      "[41/150] Loss_D: 0.0020 Loss_G: 0.0063 D(x): 0.9991 D(G(z)): 0.9991: 100%|█████████████| 13/13 [01:30<00:00,  6.99s/it]\n",
      "[42/150] Loss_D: 0.0029 Loss_G: 0.0056 D(x): 0.9991 D(G(z)): 0.9991: 100%|█████████████| 13/13 [01:31<00:00,  7.06s/it]\n",
      "[43/150] Loss_D: 0.0021 Loss_G: 0.0056 D(x): 0.9996 D(G(z)): 0.9996: 100%|█████████████| 13/13 [01:43<00:00,  7.98s/it]\n",
      "[44/150] Loss_D: 0.0027 Loss_G: 0.0059 D(x): 0.9979 D(G(z)): 0.9979: 100%|█████████████| 13/13 [01:30<00:00,  6.93s/it]\n",
      "[45/150] Loss_D: 0.0011 Loss_G: 0.0061 D(x): 0.9994 D(G(z)): 0.9994: 100%|█████████████| 13/13 [01:33<00:00,  7.18s/it]\n",
      "[46/150] Loss_D: 0.0012 Loss_G: 0.0054 D(x): 0.9993 D(G(z)): 0.9993: 100%|█████████████| 13/13 [01:33<00:00,  7.21s/it]\n",
      "[47/150] Loss_D: 0.0022 Loss_G: 0.0056 D(x): 0.9989 D(G(z)): 0.9989: 100%|█████████████| 13/13 [01:26<00:00,  6.62s/it]\n",
      "[48/150] Loss_D: 0.0027 Loss_G: 0.0055 D(x): 0.9981 D(G(z)): 0.9981: 100%|█████████████| 13/13 [01:29<00:00,  6.89s/it]\n",
      "[49/150] Loss_D: 0.0014 Loss_G: 0.0055 D(x): 0.9995 D(G(z)): 0.9995: 100%|█████████████| 13/13 [01:27<00:00,  6.71s/it]\n",
      "[50/150] Loss_D: 0.0011 Loss_G: 0.0051 D(x): 0.9997 D(G(z)): 0.9997:   8%|█             | 1/13 [00:06<01:12,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[50/150] Loss_D: 0.0013 Loss_G: 0.0053 D(x): 0.9993 D(G(z)): 0.9993:  15%|██▏           | 2/13 [00:12<01:12,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[50/150] Loss_D: 0.0010 Loss_G: 0.0053 D(x): 0.9995 D(G(z)): 0.9995:  23%|███▏          | 3/13 [00:19<01:03,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[50/150] Loss_D: 0.0016 Loss_G: 0.0051 D(x): 0.9989 D(G(z)): 0.9989:  31%|████▎         | 4/13 [00:25<00:58,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[50/150] Loss_D: 0.0017 Loss_G: 0.0051 D(x): 0.9991 D(G(z)): 0.9991:  38%|█████▍        | 5/13 [00:32<00:51,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[50/150] Loss_D: 0.0030 Loss_G: 0.0051 D(x): 0.9991 D(G(z)): 0.9991:  46%|██████▍       | 6/13 [00:41<00:52,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[50/150] Loss_D: 0.0026 Loss_G: 0.0051 D(x): 0.9992 D(G(z)): 0.9992:  54%|███████▌      | 7/13 [00:47<00:42,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[50/150] Loss_D: 0.0024 Loss_G: 0.0051 D(x): 0.9992 D(G(z)): 0.9992:  62%|████████▌     | 8/13 [00:55<00:35,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[50/150] Loss_D: 0.0022 Loss_G: 0.0053 D(x): 0.9993 D(G(z)): 0.9993:  69%|█████████▋    | 9/13 [01:01<00:27,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[50/150] Loss_D: 0.0021 Loss_G: 0.0054 D(x): 0.9993 D(G(z)): 0.9993:  77%|██████████   | 10/13 [01:10<00:22,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[50/150] Loss_D: 0.0020 Loss_G: 0.0054 D(x): 0.9993 D(G(z)): 0.9993:  85%|███████████  | 11/13 [01:16<00:14,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[50/150] Loss_D: 0.0019 Loss_G: 0.0054 D(x): 0.9993 D(G(z)): 0.9993:  92%|████████████ | 12/13 [01:25<00:07,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[50/150] Loss_D: 0.0019 Loss_G: 0.0054 D(x): 0.9993 D(G(z)): 0.9993: 100%|█████████████| 13/13 [01:29<00:00,  6.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[51/150] Loss_D: 0.0018 Loss_G: 0.0052 D(x): 0.9994 D(G(z)): 0.9994: 100%|█████████████| 13/13 [01:31<00:00,  7.07s/it]\n",
      "[52/150] Loss_D: 0.0010 Loss_G: 0.0058 D(x): 0.9994 D(G(z)): 0.9994: 100%|█████████████| 13/13 [01:26<00:00,  6.66s/it]\n",
      "[53/150] Loss_D: 0.0016 Loss_G: 0.0057 D(x): 0.9989 D(G(z)): 0.9989: 100%|█████████████| 13/13 [01:32<00:00,  7.13s/it]\n",
      "[54/150] Loss_D: 0.0015 Loss_G: 0.0052 D(x): 0.9994 D(G(z)): 0.9994: 100%|█████████████| 13/13 [01:33<00:00,  7.18s/it]\n",
      "[55/150] Loss_D: 0.0023 Loss_G: 0.0057 D(x): 0.9987 D(G(z)): 0.9987: 100%|█████████████| 13/13 [01:22<00:00,  6.37s/it]\n",
      "[56/150] Loss_D: 0.0010 Loss_G: 0.0060 D(x): 0.9996 D(G(z)): 0.9996: 100%|█████████████| 13/13 [01:35<00:00,  7.34s/it]\n",
      "[57/150] Loss_D: 0.0032 Loss_G: 0.0055 D(x): 0.9976 D(G(z)): 0.9976: 100%|█████████████| 13/13 [01:21<00:00,  6.29s/it]\n",
      "[58/150] Loss_D: 0.6885 Loss_G: 0.0048 D(x): 0.8514 D(G(z)): 0.8514: 100%|█████████████| 13/13 [01:34<00:00,  7.26s/it]\n",
      "[59/150] Loss_D: 0.8516 Loss_G: 0.0050 D(x): 0.5807 D(G(z)): 0.5807: 100%|█████████████| 13/13 [01:32<00:00,  7.13s/it]\n",
      "[60/150] Loss_D: 0.4896 Loss_G: 0.0055 D(x): 0.8693 D(G(z)): 0.8693: 100%|█████████████| 13/13 [01:27<00:00,  6.73s/it]\n",
      "[61/150] Loss_D: 0.2509 Loss_G: 0.0051 D(x): 0.9545 D(G(z)): 0.9545: 100%|█████████████| 13/13 [01:38<00:00,  7.55s/it]\n",
      "[62/150] Loss_D: 0.3011 Loss_G: 0.0051 D(x): 0.9338 D(G(z)): 0.9338: 100%|█████████████| 13/13 [01:21<00:00,  6.28s/it]\n",
      "[63/150] Loss_D: 0.0815 Loss_G: 0.0051 D(x): 0.9669 D(G(z)): 0.9669: 100%|█████████████| 13/13 [01:28<00:00,  6.78s/it]\n",
      "[64/150] Loss_D: 0.0193 Loss_G: 0.0053 D(x): 0.9915 D(G(z)): 0.9915: 100%|█████████████| 13/13 [01:22<00:00,  6.36s/it]\n",
      "[65/150] Loss_D: 0.0086 Loss_G: 0.0052 D(x): 0.9963 D(G(z)): 0.9963: 100%|█████████████| 13/13 [01:27<00:00,  6.74s/it]\n",
      "[66/150] Loss_D: 0.0042 Loss_G: 0.0058 D(x): 0.9974 D(G(z)): 0.9974: 100%|█████████████| 13/13 [01:32<00:00,  7.08s/it]\n",
      "[67/150] Loss_D: 0.0059 Loss_G: 0.0051 D(x): 0.9954 D(G(z)): 0.9954: 100%|█████████████| 13/13 [01:34<00:00,  7.28s/it]\n",
      "[68/150] Loss_D: 0.0048 Loss_G: 0.0052 D(x): 0.9982 D(G(z)): 0.9982: 100%|█████████████| 13/13 [01:29<00:00,  6.85s/it]\n",
      "[69/150] Loss_D: 0.0030 Loss_G: 0.0059 D(x): 0.9985 D(G(z)): 0.9985: 100%|█████████████| 13/13 [01:32<00:00,  7.13s/it]\n",
      "[70/150] Loss_D: 0.0028 Loss_G: 0.0055 D(x): 0.9986 D(G(z)): 0.9986: 100%|█████████████| 13/13 [01:23<00:00,  6.45s/it]\n",
      "[71/150] Loss_D: 0.0020 Loss_G: 0.0053 D(x): 0.9991 D(G(z)): 0.9991: 100%|█████████████| 13/13 [01:30<00:00,  6.95s/it]\n",
      "[72/150] Loss_D: 0.0018 Loss_G: 0.0049 D(x): 0.9987 D(G(z)): 0.9987: 100%|█████████████| 13/13 [01:25<00:00,  6.57s/it]\n",
      "[73/150] Loss_D: 0.0012 Loss_G: 0.0051 D(x): 0.9992 D(G(z)): 0.9992: 100%|█████████████| 13/13 [01:46<00:00,  8.23s/it]\n",
      "[74/150] Loss_D: 0.0011 Loss_G: 0.0050 D(x): 0.9996 D(G(z)): 0.9996: 100%|█████████████| 13/13 [01:21<00:00,  6.26s/it]\n",
      "[75/150] Loss_D: 0.0025 Loss_G: 0.0053 D(x): 0.9986 D(G(z)): 0.9986: 100%|█████████████| 13/13 [01:43<00:00,  7.95s/it]\n",
      "[76/150] Loss_D: 0.0014 Loss_G: 0.0049 D(x): 0.9993 D(G(z)): 0.9993: 100%|█████████████| 13/13 [01:38<00:00,  7.55s/it]\n",
      "[77/150] Loss_D: 0.0012 Loss_G: 0.0051 D(x): 0.9994 D(G(z)): 0.9994: 100%|█████████████| 13/13 [01:44<00:00,  8.00s/it]\n",
      "[78/150] Loss_D: 0.0012 Loss_G: 0.0048 D(x): 0.9995 D(G(z)): 0.9995: 100%|█████████████| 13/13 [01:34<00:00,  7.24s/it]\n",
      "[79/150] Loss_D: 0.0009 Loss_G: 0.0050 D(x): 0.9996 D(G(z)): 0.9996: 100%|█████████████| 13/13 [01:24<00:00,  6.50s/it]\n",
      "[80/150] Loss_D: 0.0007 Loss_G: 0.0052 D(x): 0.9996 D(G(z)): 0.9996: 100%|█████████████| 13/13 [01:19<00:00,  6.14s/it]\n",
      "[81/150] Loss_D: 0.0008 Loss_G: 0.0053 D(x): 0.9998 D(G(z)): 0.9998: 100%|█████████████| 13/13 [01:36<00:00,  7.40s/it]\n",
      "[82/150] Loss_D: 0.0014 Loss_G: 0.0049 D(x): 0.9990 D(G(z)): 0.9990: 100%|█████████████| 13/13 [01:23<00:00,  6.39s/it]\n",
      "[83/150] Loss_D: 0.0011 Loss_G: 0.0049 D(x): 0.9996 D(G(z)): 0.9996: 100%|█████████████| 13/13 [01:26<00:00,  6.67s/it]\n",
      "[84/150] Loss_D: 0.0005 Loss_G: 0.0050 D(x): 0.9997 D(G(z)): 0.9997: 100%|█████████████| 13/13 [01:21<00:00,  6.25s/it]\n",
      "[85/150] Loss_D: 0.0007 Loss_G: 0.0051 D(x): 0.9996 D(G(z)): 0.9996: 100%|█████████████| 13/13 [01:40<00:00,  7.72s/it]\n",
      "[86/150] Loss_D: 0.0006 Loss_G: 0.0049 D(x): 0.9998 D(G(z)): 0.9998: 100%|█████████████| 13/13 [01:24<00:00,  6.50s/it]\n",
      "[87/150] Loss_D: 0.0006 Loss_G: 0.0049 D(x): 0.9997 D(G(z)): 0.9997: 100%|█████████████| 13/13 [01:38<00:00,  7.61s/it]\n",
      "[88/150] Loss_D: 0.0004 Loss_G: 0.0050 D(x): 0.9998 D(G(z)): 0.9998: 100%|█████████████| 13/13 [01:28<00:00,  6.79s/it]\n",
      "[89/150] Loss_D: 0.0005 Loss_G: 0.0048 D(x): 0.9998 D(G(z)): 0.9998: 100%|█████████████| 13/13 [01:38<00:00,  7.60s/it]\n",
      "[90/150] Loss_D: 0.0004 Loss_G: 0.0048 D(x): 0.9998 D(G(z)): 0.9998: 100%|█████████████| 13/13 [01:20<00:00,  6.20s/it]\n",
      "[91/150] Loss_D: 0.0003 Loss_G: 0.0051 D(x): 0.9998 D(G(z)): 0.9998: 100%|█████████████| 13/13 [01:33<00:00,  7.23s/it]\n",
      "[92/150] Loss_D: 0.0005 Loss_G: 0.0049 D(x): 0.9997 D(G(z)): 0.9997: 100%|█████████████| 13/13 [01:25<00:00,  6.57s/it]\n",
      "[93/150] Loss_D: 0.0003 Loss_G: 0.0049 D(x): 0.9998 D(G(z)): 0.9998: 100%|█████████████| 13/13 [01:33<00:00,  7.18s/it]\n",
      "[94/150] Loss_D: 0.0005 Loss_G: 0.0048 D(x): 0.9998 D(G(z)): 0.9998: 100%|█████████████| 13/13 [01:27<00:00,  6.73s/it]\n",
      "[95/150] Loss_D: 0.0005 Loss_G: 0.0052 D(x): 0.9998 D(G(z)): 0.9998: 100%|█████████████| 13/13 [01:34<00:00,  7.29s/it]\n",
      "[96/150] Loss_D: 0.0005 Loss_G: 0.0050 D(x): 0.9997 D(G(z)): 0.9997: 100%|█████████████| 13/13 [01:27<00:00,  6.70s/it]\n",
      "[97/150] Loss_D: 0.0004 Loss_G: 0.0047 D(x): 0.9998 D(G(z)): 0.9998: 100%|█████████████| 13/13 [01:34<00:00,  7.26s/it]\n",
      "[98/150] Loss_D: 0.0005 Loss_G: 0.0051 D(x): 0.9996 D(G(z)): 0.9996: 100%|█████████████| 13/13 [01:28<00:00,  6.82s/it]\n",
      "[99/150] Loss_D: 0.0006 Loss_G: 0.0049 D(x): 0.9997 D(G(z)): 0.9997: 100%|█████████████| 13/13 [01:36<00:00,  7.41s/it]\n",
      "[100/150] Loss_D: 0.0001 Loss_G: 0.0041 D(x): 1.0000 D(G(z)): 1.0000:   8%|█            | 1/13 [00:06<01:16,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[100/150] Loss_D: 0.0001 Loss_G: 0.0045 D(x): 1.0000 D(G(z)): 1.0000:  15%|██           | 2/13 [00:13<01:13,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[100/150] Loss_D: 0.0007 Loss_G: 0.0047 D(x): 0.9995 D(G(z)): 0.9995:  23%|███          | 3/13 [00:18<01:02,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[100/150] Loss_D: 0.0005 Loss_G: 0.0048 D(x): 0.9996 D(G(z)): 0.9996:  31%|████         | 4/13 [00:25<00:57,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[100/150] Loss_D: 0.0005 Loss_G: 0.0047 D(x): 0.9997 D(G(z)): 0.9997:  38%|█████        | 5/13 [00:33<00:56,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[100/150] Loss_D: 0.0004 Loss_G: 0.0048 D(x): 0.9997 D(G(z)): 0.9997:  46%|██████       | 6/13 [00:40<00:49,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[100/150] Loss_D: 0.0004 Loss_G: 0.0050 D(x): 0.9998 D(G(z)): 0.9998:  54%|███████      | 7/13 [00:46<00:40,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[100/150] Loss_D: 0.0003 Loss_G: 0.0050 D(x): 0.9998 D(G(z)): 0.9998:  62%|████████     | 8/13 [00:53<00:33,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[100/150] Loss_D: 0.0003 Loss_G: 0.0050 D(x): 0.9998 D(G(z)): 0.9998:  69%|█████████    | 9/13 [00:59<00:26,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[100/150] Loss_D: 0.0004 Loss_G: 0.0050 D(x): 0.9998 D(G(z)): 0.9998:  77%|█████████▏  | 10/13 [01:07<00:20,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[100/150] Loss_D: 0.0004 Loss_G: 0.0049 D(x): 0.9998 D(G(z)): 0.9998:  85%|██████████▏ | 11/13 [01:13<00:13,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[100/150] Loss_D: 0.0004 Loss_G: 0.0049 D(x): 0.9998 D(G(z)): 0.9998:  92%|███████████ | 12/13 [01:20<00:06,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[100/150] Loss_D: 0.0004 Loss_G: 0.0048 D(x): 0.9997 D(G(z)): 0.9997: 100%|████████████| 13/13 [01:24<00:00,  6.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> saving checkpoint\n",
      "Saved Generator Checkpoint\n",
      "===> saving checkpoint\n",
      "Saved Discriminator Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[101/150] Loss_D: 0.0003 Loss_G: 0.0054 D(x): 1.0000 D(G(z)): 1.0000: 100%|████████████| 13/13 [01:52<00:00,  8.65s/it]\n",
      "[102/150] Loss_D: 0.0004 Loss_G: 0.0049 D(x): 0.9998 D(G(z)): 0.9998: 100%|████████████| 13/13 [01:31<00:00,  7.02s/it]\n",
      "[103/150] Loss_D: 0.0001 Loss_G: 0.0048 D(x): 0.9999 D(G(z)): 0.9999: 100%|████████████| 13/13 [01:32<00:00,  7.08s/it]\n",
      "[104/150] Loss_D: 0.0004 Loss_G: 0.0052 D(x): 0.9998 D(G(z)): 0.9998: 100%|████████████| 13/13 [01:34<00:00,  7.27s/it]\n",
      "[105/150] Loss_D: 0.0001 Loss_G: 0.0048 D(x): 0.9999 D(G(z)): 0.9999: 100%|████████████| 13/13 [01:38<00:00,  7.57s/it]\n",
      "[106/150] Loss_D: 0.0003 Loss_G: 0.0047 D(x): 0.9998 D(G(z)): 0.9998: 100%|████████████| 13/13 [04:37<00:00, 21.35s/it]\n",
      "[107/150] Loss_D: 0.0003 Loss_G: 0.0048 D(x): 0.9998 D(G(z)): 0.9998: 100%|████████████| 13/13 [02:42<00:00, 12.53s/it]\n",
      "[108/150] Loss_D: 0.0003 Loss_G: 0.0048 D(x): 0.9998 D(G(z)): 0.9998: 100%|████████████| 13/13 [02:39<00:00, 12.27s/it]\n",
      "[109/150] Loss_D: 0.0004 Loss_G: 0.0048 D(x): 0.9997 D(G(z)): 0.9997: 100%|████████████| 13/13 [02:52<00:00, 13.29s/it]\n",
      "[110/150] Loss_D: 0.0005 Loss_G: 0.0046 D(x): 0.9999 D(G(z)): 0.9999: 100%|████████████| 13/13 [02:39<00:00, 12.24s/it]\n",
      "[111/150] Loss_D: 0.0002 Loss_G: 0.0047 D(x): 0.9999 D(G(z)): 0.9999: 100%|████████████| 13/13 [02:13<00:00, 10.28s/it]\n",
      "[112/150] Loss_D: 0.0003 Loss_G: 0.0047 D(x): 0.9998 D(G(z)): 0.9998: 100%|████████████| 13/13 [01:39<00:00,  7.62s/it]\n",
      "[113/150] Loss_D: 0.0005 Loss_G: 0.0047 D(x): 0.9999 D(G(z)): 0.9999: 100%|████████████| 13/13 [02:08<00:00,  9.88s/it]\n",
      "[114/150] Loss_D: 0.0002 Loss_G: 0.0046 D(x): 0.9999 D(G(z)): 0.9999: 100%|████████████| 13/13 [01:54<00:00,  8.78s/it]\n",
      "[115/150] Loss_D: 0.0004 Loss_G: 0.0048 D(x): 0.9998 D(G(z)): 0.9998: 100%|████████████| 13/13 [01:48<00:00,  8.38s/it]\n",
      "[116/150] Loss_D: 0.0004 Loss_G: 0.0050 D(x): 0.9999 D(G(z)): 0.9999: 100%|████████████| 13/13 [01:49<00:00,  8.45s/it]\n",
      "[117/150] Loss_D: 0.0003 Loss_G: 0.0049 D(x): 0.9998 D(G(z)): 0.9998: 100%|████████████| 13/13 [01:47<00:00,  8.31s/it]\n",
      "[118/150] Loss_D: 0.0004 Loss_G: 0.0047 D(x): 0.9999 D(G(z)): 0.9999:  85%|██████████▏ | 11/13 [01:39<00:18,  9.02s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "  train_bar = tqdm(trainloader)\n",
    "  running_results = {'batch_sizes':0, 'd_loss':0,\n",
    "                     \"g_loss\":0, \"d_score\":0, \"g_score\":0}\n",
    "\n",
    "  netG.train()\n",
    "  netD.train()\n",
    "  for data, target in train_bar:\n",
    "    g_update_first = True\n",
    "    batch_size = data.size(0)\n",
    "    running_results['batch_sizes'] += batch_size\n",
    "\n",
    "    real_img = Variable(target)\n",
    "    real_img = real_img.to(device)\n",
    "    z = Variable(data)\n",
    "    z = z.to(device)\n",
    "\n",
    "    ## Update Discriminator ##\n",
    "    fake_img = netG(z)\n",
    "    netD.zero_grad()\n",
    "    real_out = netD(real_img).mean()\n",
    "    fake_out = netD(fake_img).mean()\n",
    "    d_loss = 1 - real_out + fake_out\n",
    "    d_loss.backward(retain_graph = True)\n",
    "    optimizerD.step()\n",
    "\n",
    "    ## Now update Generator\n",
    "    fake_img = netG(z)\n",
    "    fake_out = netD(fake_img).mean()\n",
    "    netG.zero_grad()\n",
    "    g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
    "    g_loss.backward()\n",
    "\n",
    "    fake_img = netG(z)\n",
    "    fake_out = netD(fake_img).mean()\n",
    "\n",
    "    optimizerG.step()\n",
    "\n",
    "    running_results['g_loss'] += g_loss.item() * batch_size\n",
    "    running_results['d_loss'] += d_loss.item() * batch_size\n",
    "    running_results['d_score'] += real_out.item() * batch_size\n",
    "    running_results['g_score'] += real_out.item() * batch_size\n",
    "\n",
    "    ## Updating the progress bar\n",
    "    train_bar.set_description(desc=\"[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f\" % (\n",
    "        epoch, N_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],\n",
    "        running_results['g_loss'] / running_results['batch_sizes'],\n",
    "        running_results['d_score'] / running_results['batch_sizes'],\n",
    "        running_results['g_score'] / running_results['batch_sizes']\n",
    "    ))\n",
    "  if epoch%50==0:\n",
    "        saveCheckpoint(netG, optimizerG, filename='checkpoints/generator_checkpoint.pth')\n",
    "        print(f'Saved Generator Checkpoint')\n",
    "        saveCheckpoint(netD, optimizerD, filename='checkpoints/discriminator_checkpoint.pth')\n",
    "        print(f'Saved Discriminator Checkpoint')  \n",
    "  netG.eval()\n",
    "print(f'Total Training Time: {(t0 - time())/3600} Hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0u95d5GJkfAf"
   },
   "source": [
    "# An attempt at testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(input_file, save_image=False):\n",
    "    '''\n",
    "    This function passes an image into the model, and retrieves its input. \n",
    "    Need to implement model saving and checkpointing. \n",
    "    '''\n",
    "    # Read input image and convert to Tensor for feeding into model\n",
    "    image = cv2.imread(input_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Need to add this as OpenCV uses BGR instead of RGB\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    in_tensor = transform(image)\n",
    "    \n",
    "    # Feed input tensor into model\n",
    "    in_tensor = in_tensor.to(device) # Send input to device, can cause problems if input tensor is on CPU and Model on GPU!!\n",
    "    out_tensor = netG(in_tensor.unsqueeze(0))\n",
    "    \n",
    "    # Final transformations, as for some reason, output is rotated\n",
    "    display_tensor = out_tensor.to('cpu') # send output tensor back to CPU\n",
    "    display_tensor = display_tensor.detach().numpy()\n",
    "    display_tensor = np.transpose(display_tensor)\n",
    "    display_tensor = np.squeeze(display_tensor)\n",
    "    display_tensor = cv2.flip(display_tensor, 0)\n",
    "    display_tensor = rotate(display_tensor, -90)\n",
    "    \n",
    "    if save_image: \n",
    "        f = (display_tensor * 255).astype(np.uint8) \n",
    "        out_file = input('What name do you want to save the image as: ')\n",
    "        cv2.imwrite(f'{out_file}.png', t)\n",
    "    \n",
    "    return display_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = testModel('source/test_images/barbara_test.png')\n",
    "i = cv2.imread('source/test_images/barbara_test.png')\n",
    "i = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,8))\n",
    "ax[0].imshow(i)\n",
    "ax[0].set_title('Input Image')\n",
    "ax[1].imshow(a)\n",
    "ax[1].set_title('Output Image')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "srgan",
   "language": "python",
   "name": "srgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

